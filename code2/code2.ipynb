{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment 2\n",
    "\n",
    "Authors:\n",
    "* Ryan Fogle\n",
    "    - rsfogle2@illinois.edu\n",
    "    - UIN: 652628818\n",
    "* Sean Enright\n",
    "    - seanre2@illinois.edu\n",
    "    - UNIN: 661791377"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implement Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = pd.read_csv(\"Coding2_Data.csv\")\n",
    "var_names = myData.columns\n",
    "y = myData[['Y']].to_numpy()\n",
    "X = myData.drop(['Y'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CD for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "\n",
    "def one_var_lasso(r: npt.NDArray, x: npt.NDArray, lam):\n",
    "    \n",
    "    #################\n",
    "    # Your CODE\n",
    "    #################\n",
    "    \n",
    "    # x == z\n",
    "    # v == r\n",
    "\n",
    "    z2 = (x.T @ x).sum()\n",
    "    a = r.T @ x / z2\n",
    "    n = 2 * x.shape[0] * lam / z2\n",
    "\n",
    "    if a > n/2:\n",
    "        return a - n/2\n",
    "    elif np.abs(a) <= n/2:\n",
    "        return 0\n",
    "    elif a < -n/2:\n",
    "        return a + n/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def MyLasso(X, y, lam_seq, maxit = 100):\n",
    "    \n",
    "    # Input\n",
    "    # X: n-by-p design matrix without the intercept \n",
    "    # y: n-by-1 response vector \n",
    "    # lam.seq: sequence of lambda values (arranged from large to small)\n",
    "    # maxit: number of updates for each lambda \n",
    "    \n",
    "    # Output\n",
    "    # B: a (p+1)-by-len(lam.seq) coefficient matrix \n",
    "    #    with the first row being the intercept sequence \n",
    "\n",
    "  \n",
    "    n, p = X.shape\n",
    "    nlam = len(lam_seq)\n",
    "    B = np.zeros((p+1, nlam))\n",
    "    \n",
    "    ##############################\n",
    "    # YOUR CODE: \n",
    "    # (1) newX = Standardizad X; \n",
    "    # (2) Record the centers and scales used in (1) \n",
    "    ##############################\n",
    "    \n",
    "    # Centers\n",
    "    y_mean = y.mean()\n",
    "    X_mean = X.mean(axis=0)\n",
    "\n",
    "    # Scale\n",
    "    X_se = X.std(axis=0)\n",
    "\n",
    "    # Centering and scaling of X\n",
    "    newX = (X - X_mean) / X_se\n",
    "\n",
    "    # Initilize coef vector b and residual vector r\n",
    "    b = np.zeros(p)\n",
    "    r = y\n",
    "    \n",
    "    # Triple nested loop\n",
    "    for m in range(nlam):\n",
    "        for step in range(maxit):\n",
    "            for j in range(p):\n",
    "                X_j = newX[:, j].reshape(-1,1)\n",
    "                r = r + X_j * b[j]\n",
    "                b[j] = one_var_lasso(r, X_j, lam_seq[m])\n",
    "                r = r - X_j * b[j]\n",
    "        B[1:, m] = b \n",
    "    \n",
    "    ##############################\n",
    "    # YOUR CODE:\n",
    "    # Scale back the coefficients;\n",
    "    # Update the intercepts stored in B[, 1]\n",
    "    ##############################\n",
    "\n",
    "    # Scale back\n",
    "    B[1:, :] = B[1:, :] / X_se[:, np.newaxis]\n",
    "    \n",
    "    # Add in new intercepts\n",
    "    B[0, :] = y_mean - (X_mean[np.newaxis, :] @ B[1:, :]).squeeze()\n",
    "    \n",
    "    return(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lam_seq = np.linspace(-1, -8, num = 80)\n",
    "lam_seq = np.exp(log_lam_seq)\n",
    "myout = MyLasso(X, y, lam_seq, maxit = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, _ = myout.shape\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "for i in range(p-1):\n",
    "    plt.plot(log_lam_seq, myout[i+1, :], label = var_names[i])\n",
    "\n",
    "plt.xlabel('Log Lambda')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso Paths - Numpy implementation')\n",
    "plt.legend()\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Accuracy\n",
    "The output of our algorithm is compared against the output from glmnet. The maximum difference between the two coefficient matrices should be lass than 0.005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef = pd.read_csv(\"Coding2_lasso_coefs.csv\").to_numpy()\n",
    "lasso_coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(myout - lasso_coef).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Simulation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Six Procedures\n",
    "\n",
    "The following code is shared by both Case I and Case II below.\n",
    "\n",
    "Six prediction procedures are defined:\n",
    "* Linear regression with all features\n",
    "* Ridge regression using `lambda.min`\n",
    "* Lasso with `lambda.min`\n",
    "* Lasso with `lambda.1se`\n",
    "* Lasso refit from the model with `lambda.1se`\n",
    "* Principal components regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCR(object):\n",
    "\n",
    "    def __init__(self, num_folds=10):\n",
    "        self.folds = num_folds\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        n, p = X.shape\n",
    "        indices = np.arange(n)\n",
    "        np.random.shuffle(indices)\n",
    "        index_sets = np.array_split(indices, self.folds)\n",
    "        ncomp = min(p, n - 1 - max([len(i) for i in index_sets]))\n",
    "        cv_err = np.zeros(ncomp)\n",
    "\n",
    "        for ifold in range(self.folds):\n",
    "            train_inds =  np.delete(index_sets, obj=ifold, axis=0).ravel()\n",
    "            test_inds = index_sets[ifold]\n",
    "\n",
    "            X_train = X[train_inds, :]\n",
    "            pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA())])\n",
    "            pipeline.fit(X_train)\n",
    "            X_train = pipeline.transform(X_train)\n",
    "            coefs = Y[train_inds].T @ X_train / np.sum(X_train**2, axis=0)\n",
    "            b0 = np.mean(Y[train_inds])\n",
    "\n",
    "            X_test = pipeline.transform(X[test_inds, :])\n",
    "\n",
    "            for k in np.arange(ncomp):\n",
    "                preds = X_test[:, :k] @ coefs.T[:k] + b0\n",
    "                cv_err[k] += cv_err[k] + np.sum((Y[test_inds]-preds)**2)\n",
    "\n",
    "        min_ind = np.argmin(cv_err)\n",
    "        self.ncomp = min_ind+1\n",
    "        pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=self.ncomp))])\n",
    "        self.transform = pipeline.fit(X)\n",
    "        self.model = LinearRegression().fit(self.transform.transform(X), Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_ = self.transform.transform(X)\n",
    "        return self.model.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoBase:\n",
    "    \"\"\"Predict with Lasso Regression variants\n",
    "        Note: X_train and X_test must be centered and scaled\"\"\"\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        # Lasso\n",
    "        lasso_alphas = np.logspace(-10, 1, 100)\n",
    "        lassocv = LassoCV(alphas = lasso_alphas, cv = 10)\n",
    "        lassocv.fit(X_train, y_train)\n",
    "        cv_alphas = lassocv.alphas_\n",
    "        mean_mse = np.mean(lassocv.mse_path_, axis=1)\n",
    "        min_idx = np.argmin(mean_mse)\n",
    "\n",
    "        # Minimum\n",
    "        self.alpha_min = cv_alphas[min_idx]\n",
    "\n",
    "        # 1se\n",
    "        std_mse = np.std(lassocv.mse_path_, axis=1) / np.sqrt(10) \n",
    "        threshold = mean_mse[min_idx] + std_mse[min_idx]\n",
    "        self.alpha_1se = max(cv_alphas[np.where(mean_mse <= threshold)])\n",
    "\n",
    "        # Refit\n",
    "        self.nonzero_indices = None\n",
    "    \n",
    "    def min(self, X_test):\n",
    "        \"\"\"Regression with lambda.min\"\"\"\n",
    "        lasso_model_min = Lasso(alpha = self.alpha_min, max_iter=10000)\n",
    "        lasso_model_min.fit(self.X_train, self.y_train)\n",
    "        return lasso_model_min.predict(X_test)\n",
    "    \n",
    "    def one_se(self, X_test):\n",
    "        \"\"\"Regression with lambda.1se\"\"\"\n",
    "        lasso_model_1se = Lasso(alpha = self.alpha_1se, max_iter=10000)\n",
    "        lasso_model_1se.fit(self.X_train, self.y_train)\n",
    "        self.nonzero_indices = np.where(lasso_model_1se.coef_ != 0)[0]\n",
    "        return lasso_model_1se.predict(X_test)\n",
    "    \n",
    "    def refit(self, X_test):\n",
    "        \"\"\"Refit regression from lambda.1se\"\"\"\n",
    "        lm_refit = LinearRegression()\n",
    "        lm_refit.fit(self.X_train.iloc[:, self.nonzero_indices],\n",
    "                     self.y_train)\n",
    "        return lm_refit.predict(X_test.iloc[:, self.nonzero_indices])\n",
    "\n",
    "\n",
    "def full_model(X_train, y_train, X_test):\n",
    "    \"\"\"Predict with Full Linear Model\"\"\"\n",
    "    full = LinearRegression()\n",
    "    full.fit(X_train, y_train)\n",
    "    return full.predict(X_test)\n",
    "\n",
    "def ridge_regression(X_train, y_train, X_test):\n",
    "    \"\"\"Predict with Ridge Regression\n",
    "        Note: X_train and X_test must be centered and scaled\"\"\"\n",
    "    # Ridge regression\n",
    "    ridge_alphas = np.logspace(-10, 1, 100)\n",
    "    ridgecv = RidgeCV(alphas = ridge_alphas, cv = 10,\n",
    "                      scoring = 'neg_mean_squared_error')\n",
    "    ridgecv.fit(X_train, y_train)\n",
    "    ridge_model = Ridge(alpha = ridgecv.alpha_)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    return ridge_model.predict(X_test)\n",
    "\n",
    "def principal_component_regression(X_train, y_train, X_test):\n",
    "    # perform PCR and train linear model.\n",
    "    pcr = PCR()\n",
    "    pcr.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "    return pcr.predict(X_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sim_data(X, Y, pct_test=0.25):\n",
    "    n = len(Y)\n",
    "    indices = np.arange(0, n)\n",
    "    np.random.shuffle(indices)\n",
    "    test_ind = indices[:int(np.floor(pct_test * n))]\n",
    "    train_ind = indices[len(test_ind):]\n",
    "\n",
    "    # Splitting the data into training and testing sets\n",
    "    X_train = X.iloc[train_ind]\n",
    "    y_train = Y[train_ind]\n",
    "    X_test = X.iloc[test_ind]\n",
    "    y_test = Y[test_ind]\n",
    "\n",
    "    # We need to scale data for Ridge and Lasso because they cannot normalize like R. \n",
    "    # Scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_train_scale, X_test_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case I\n",
    "\n",
    "This simulation uses the data in `Coding2_Data2.csv`, which has 91 columns (1 response and 90 predictors), and 506 observations. The first 14 columns are the same data used in Part I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/liangfgithub/liangfgithub.github.io/master/Data/Coding2_Data2.csv\"\n",
    "myData = pd.read_csv(url)\n",
    "# myData.head()\n",
    "Y = myData['Y']\n",
    "X = myData.drop(['Y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation\n",
    "\n",
    "In this simulation, each of the six models is used to for prediction with the `Coding2_Data2.csv` data, and their error is compared via mean squared prediction error (MSPE). The following procedure is carried out for 50 iterations:\n",
    "1) Partition data into 75% training and 25% test sets\n",
    "2) Fit training data with all six models, including:\n",
    "    * Linear regression with all features\n",
    "    * Ridge regression using `lambda.min`\n",
    "    * Lasso with `lambda.min`\n",
    "    * Lasso with `lambda.1se`\n",
    "    * Lasso refit from the model with `lambda.1se`\n",
    "    * Principal components regression\n",
    "3) Predict response with test data\n",
    "4) Evaluate MSPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "# Suppress convergence errors\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 6\n",
    "n_sims = 50\n",
    "data = []\n",
    "\n",
    "for i in tqdm(range(n_sims), total=n_sims):\n",
    "    X_train, y_train, X_test, y_test, X_train_scale, X_test_scale = gen_sim_data(X, Y,\n",
    "                                                                                 pct_test=0.25)\n",
    "    lasso = LassoBase(X_train, y_train)\n",
    "    predictions = (\n",
    "        mean_squared_error(y_test, full_model(X_train, y_train, X_test)),\n",
    "        mean_squared_error(y_test, ridge_regression(X_train_scale, y_train, X_test_scale)),\n",
    "        mean_squared_error(y_test, lasso.min(X_test)),\n",
    "        mean_squared_error(y_test, lasso.one_se(X_test)),\n",
    "        mean_squared_error(y_test, lasso.refit(X_test)),\n",
    "        mean_squared_error(y_test, principal_component_regression(X_train, y_train, X_test))\n",
    "    )\n",
    "    data.append(predictions)\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['Full', 'Ridge.min', 'Lasso.min', 'Lasso.1se', 'L.Refit', 'PCR'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphical Summary\n",
    "\n",
    "The MSPE for each model is presented in the boxplot and strip charts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Strip chart\n",
    "plt.title('MSPE by Model')\n",
    "sns.stripplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot\n",
    "plt.title('MSPE by Model')\n",
    "sns.boxplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
