{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment 2\n",
    "\n",
    "Author: Ryan Fogle (rsfogle2@illinois.edu)\n",
    "\n",
    "UIN: 652628818\n",
    "\n",
    "## Part 1: Implement Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = pd.read_csv(\"Coding2_Data.csv\")\n",
    "var_names = myData.columns\n",
    "y = myData[['Y']].to_numpy()\n",
    "X = myData.drop(['Y'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CD for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "\n",
    "def one_var_lasso(r: npt.NDArray, x: npt.NDArray, lam):\n",
    "    \n",
    "    #################\n",
    "    # Your CODE\n",
    "    #################\n",
    "    \n",
    "    # x == z\n",
    "    # v == r\n",
    "\n",
    "    z2 = (x.T @ x).sum()\n",
    "    a = r.T @ x / z2\n",
    "    n = 2 * x.shape[0] * lam / z2\n",
    "\n",
    "    if a > n/2:\n",
    "        return a - n/2\n",
    "    elif np.abs(a) <= n/2:\n",
    "        return 0\n",
    "    elif a < -n/2:\n",
    "        return a + n/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def MyLasso(X, y, lam_seq, maxit = 100):\n",
    "    \n",
    "    # Input\n",
    "    # X: n-by-p design matrix without the intercept \n",
    "    # y: n-by-1 response vector \n",
    "    # lam.seq: sequence of lambda values (arranged from large to small)\n",
    "    # maxit: number of updates for each lambda \n",
    "    \n",
    "    # Output\n",
    "    # B: a (p+1)-by-len(lam.seq) coefficient matrix \n",
    "    #    with the first row being the intercept sequence \n",
    "\n",
    "  \n",
    "    n, p = X.shape\n",
    "    nlam = len(lam_seq)\n",
    "    B = np.zeros((p+1, nlam))\n",
    "    \n",
    "    ##############################\n",
    "    # YOUR CODE: \n",
    "    # (1) newX = Standardizad X; \n",
    "    # (2) Record the centers and scales used in (1) \n",
    "    ##############################\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    newX = scaler.fit_transform(X)\n",
    "    # print(scaler.mean_)\n",
    "    # print(X.shape)\n",
    "\n",
    "    # Initilize coef vector b and residual vector r\n",
    "    b = np.zeros(p)\n",
    "    r = y\n",
    "\n",
    "    \n",
    "    # Triple nested loop\n",
    "    for m in range(nlam):\n",
    "        for step in range(maxit):\n",
    "            for j in range(p):\n",
    "                X_j = newX[:, j].reshape(-1,1)\n",
    "                r = r + X_j * b[j]\n",
    "                b[j] = one_var_lasso(r, X_j, lam_seq[m])\n",
    "                r = r - X_j * b[j]\n",
    "        B[1:, m] = b \n",
    "    \n",
    "    ##############################\n",
    "    # YOUR CODE:\n",
    "    # Scale back the coefficients;\n",
    "    # Update the intercepts stored in B[, 1]\n",
    "    ##############################\n",
    "\n",
    "    # scale back\n",
    "    B[1:, :] = B[1:, :] / scaler.scale_.reshape(-1,1)\n",
    "    \n",
    "    # Add in new intercepts\n",
    "    B[0, :] = (- B[1:, :] * scaler.mean_.reshape(-1, 1) / scaler.scale_.reshape(-1, 1)).sum(axis=0)\n",
    "    \n",
    "    return(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lam_seq = np.linspace(-1, -8, num = 80)\n",
    "lam_seq = np.exp(log_lam_seq)\n",
    "myout = MyLasso(X, y, lam_seq, maxit = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, _ = myout.shape\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "for i in range(p-1):\n",
    "    plt.plot(log_lam_seq, myout[i+1, :], label = var_names[i])\n",
    "\n",
    "plt.xlabel('Log Lambda')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso Paths - Numpy implementation')\n",
    "plt.legend()\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Simulation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/liangfgithub/liangfgithub.github.io/master/Data/Coding2_Data2.csv\"\n",
    "myData = pd.read_csv(url)\n",
    "# myData.head()\n",
    "Y = myData['Y']\n",
    "X = myData.drop(['Y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCR(object):\n",
    "\n",
    "    def __init__(self, num_folds=10):\n",
    "        self.folds = num_folds\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        n, p = X.shape\n",
    "        indices = np.arange(n)\n",
    "        np.random.shuffle(indices)\n",
    "        index_sets = np.array_split(indices, self.folds)\n",
    "        ncomp = min(p, n - 1 - max([len(i) for i in index_sets]))\n",
    "        cv_err = np.zeros(ncomp)\n",
    "\n",
    "        for ifold in range(self.folds):\n",
    "            train_inds =  np.delete(index_sets, obj=ifold, axis=0).ravel()\n",
    "            test_inds = index_sets[ifold]\n",
    "\n",
    "            X_train = X[train_inds, :]\n",
    "            pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA())])\n",
    "            pipeline.fit(X_train)\n",
    "            X_train = pipeline.transform(X_train)\n",
    "            coefs = Y[train_inds].T @ X_train / np.sum(X_train**2, axis=0)\n",
    "            b0 = np.mean(Y[train_inds])\n",
    "\n",
    "            X_test = pipeline.transform(X[test_inds, :])\n",
    "\n",
    "            for k in np.arange(ncomp):\n",
    "                preds = X_test[:, :k] @ coefs.T[:k] + b0\n",
    "                cv_err[k] += cv_err[k] + np.sum((Y[test_inds]-preds)**2)\n",
    "\n",
    "        min_ind = np.argmin(cv_err)\n",
    "        self.ncomp = min_ind+1\n",
    "        pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=self.ncomp))])\n",
    "        self.transform = pipeline.fit(X)\n",
    "        self.model = LinearRegression().fit(self.transform.transform(X), Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_ = self.transform.transform(X)\n",
    "        return self.model.predict(X_)\n",
    "\n",
    "def simulate(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "    \n",
    "\n",
    "    # full linear model\n",
    "    full = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Ridge regression\n",
    "    ridge_alphas = np.logspace(-10, 1, 100)\n",
    "    ridgecv = Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('ridgecv', RidgeCV(alphas = ridge_alphas, cv = 10, scoring = 'neg_mean_squared_error'))\n",
    "    ])\n",
    "    ridgecv.fit(X_train, y_train)\n",
    "    \n",
    "    ridge_model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ridge_model', Ridge(alpha = ridgecv['ridgecv'].alpha_))\n",
    "    ])\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "\n",
    "    # Lasso\n",
    "    lasso_alphas = np.logspace(-10, 1, 100)\n",
    "    lassocv = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lassocv', LassoCV(alphas = lasso_alphas, cv = 10))\n",
    "    ])\n",
    "    lassocv.fit(X_train, y_train)\n",
    "\n",
    "    mean_mse = np.mean(lassocv['lassocv'].mse_path_, axis=1)\n",
    "    std_mse = np.std(lassocv['lassocv'].mse_path_, axis=1) / np.sqrt(10) \n",
    "\n",
    "    cv_alphas = lassocv['lassocv'].alphas_\n",
    "    min_idx = np.argmin(mean_mse)\n",
    "\n",
    "    alpha_min = cv_alphas[min_idx]\n",
    "\n",
    "    threshold = mean_mse[min_idx] + std_mse[min_idx]\n",
    "    alpha_1se = max(cv_alphas[np.where(mean_mse <= threshold)])\n",
    "\n",
    "    # Lasso with alpha_min\n",
    "    lasso_model_min = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso_model_min', Lasso(alpha = alpha_min, max_iter=10000))\n",
    "    ])\n",
    "    lasso_model_min.fit(X_train, y_train)\n",
    "\n",
    "    # Lasso with alpha_1se\n",
    "    lasso_model_1se = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso_model_1se', Lasso(alpha = alpha_1se, max_iter=10000))\n",
    "        ])\n",
    "    lasso_model_1se.fit(X_train, y_train)\n",
    "\n",
    "    # Refit with alpha_1se\n",
    "    nonzero_indices = np.where(lasso_model_1se['lasso_model_1se'].coef_ != 0)[0]\n",
    "    lm_refit = LinearRegression()\n",
    "    lm_refit.fit(X_train.iloc[:, nonzero_indices], y_train)\n",
    "\n",
    "    # perform PCR and train linear model.\n",
    "    pcr = PCR()\n",
    "    pcr.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "    \n",
    "\n",
    "    return (mean_squared_error(y_test, full.predict(X_test)), # full\n",
    "            mean_squared_error(y_test, ridge_model.predict(X_test)), # ridge\n",
    "            mean_squared_error(y_test, lasso_model_min.predict(X_test)), # lasso min\n",
    "            mean_squared_error(y_test, lasso_model_1se.predict(X_test)), # lasso 1se\n",
    "            mean_squared_error(y_test, lm_refit.predict(X_test)), # lasso 1se refit\n",
    "            mean_squared_error(y_test, pcr.predict(X_test.to_numpy()))\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "data = []\n",
    "n_sims = 50\n",
    "\n",
    "for i in tqdm(range(n_sims), total=n_sims):\n",
    "    data.append(simulate(X,Y))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Full', 'Ridge.min', 'Lasso.min', 'Lasso.1se', 'L.Refit', 'PCR'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
