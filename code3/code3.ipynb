{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment 3\n",
    "\n",
    "CS 598 Practical Statistical Learning\n",
    "\n",
    "2023-10-09\n",
    "\n",
    "UIUC Fall 2023\n",
    "\n",
    "**Authors**\n",
    "* Ryan Fogle\n",
    "    - rsfogle2@illinois.edu\n",
    "    - UIN: 652628818\n",
    "* Sean Enright\n",
    "    - seanre2@illinois.edu\n",
    "    - UIN: 661791377\n",
    "\n",
    "**Contributions**\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I\n",
    "\n",
    "Here we implement LOO-CV and GCV to select the optimal span for LOESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random seed is set to ensure repeatability. The seed is the sum of our UINs. We add 1 to the sum to give a more favorable seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to the last four digits of our UINs\n",
    "np.random.seed(8818 + 1377 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 imports\n",
    "from csaps import csaps\n",
    "from skmisc.loess import loess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual calculation of smoothing matrix\n",
    "def smooth(x, y, fx, lam, axis=-1):\n",
    "    \"\"\"Fits a cubic spline to a given set of points, parameterized by lambda.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Observations vector\n",
    "        y (np.ndarray): Response vector\n",
    "        fx (np.ndarray): Data sites for output smoothed data\n",
    "        lam (float): Smoothing parameter (lambda)\n",
    "        axis (np.ndarray): Axis along which y data varies\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray): Smoothed y data\n",
    "    \"\"\"\n",
    "    p = 1 / (lam + 1) # CSAPS parameterizes by p, rather than R's lambda\n",
    "    return csaps(x, y, fx, smooth=p, axis=axis)\n",
    "\n",
    "def S_lam(x, lam):\n",
    "    \"\"\"Calculate the smoothing spline matrix for a vector observations and lambda value.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Vector of observations\n",
    "        lam (float): Smoothing parameter\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray): n x n smoothing matrix\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    Y = np.identity(n)\n",
    "    A = smooth(x, Y, x, lam, axis=0)\n",
    "    return (A + A.T) / 2\n",
    "\n",
    "def lo_lev(x, sp):\n",
    "    # Calculate diagonal entries of S, the smoothing matrix\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onestep_cv(x, y, sp):\n",
    "    # 1) Fit a LOESS model y - x with span and extract the\n",
    "    #    corresponding residual vector\n",
    "    loess_fit = loess(x, y, span=sp)\n",
    "    y_hat = loess_fit.predict(x).values\n",
    "    # 2) Call lo_lev to obtain the diagonal entries of S\n",
    "    s_ii = loess_fit.outputs.diagonal\n",
    "    #s_ii = lo_lev(x, sp)\n",
    "    # 3) Compute LOO-CV and GCV\n",
    "    # LOOCV\n",
    "    loocv = np.mean(np.power((y - y_hat) / (1 - s_ii), 2))\n",
    "    # GCV\n",
    "    m = np.mean(s_ii)\n",
    "    gcv = np.mean(np.power((y - y_hat) / (1 - m), 2))\n",
    "    return loocv, gcv\n",
    "\n",
    "def find_cv_vals(x, y, span):\n",
    "    m = len(span)\n",
    "    cv = np.zeros(m)\n",
    "    gcv = np.zeros(m)\n",
    "\n",
    "    for i in range(m):\n",
    "        cv_i, gcv_i = onestep_cv(x, y, span[i])\n",
    "        cv[i] = cv_i\n",
    "        gcv[i] = gcv_i\n",
    "    return cv, gcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining span values that produce the lowest LOOCV and GCV error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://liangfgithub.github.io/Data/Coding3_Data.csv\n",
    "data_part1 = pd.read_csv(\"Coding3_Data.csv\")\n",
    "span_vec = np.linspace(0.2, 0.9, 15)\n",
    "\n",
    "# Find optimal span by LOOCV and GCV\n",
    "loo, gcv = find_cv_vals(data_part1[\"x\"], data_part1[\"y\"], span_vec)\n",
    "\n",
    "# Display table of CV results\n",
    "print(\"Span    LOOCV   GCV\")\n",
    "for s, l, g in zip(span_vec, loo, gcv):\n",
    "    print(f\"{s:.2f}\\t{l:.3f}\\t{g:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The span optimization results are presented in the chart below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "plt.scatter(span_vec, loo, color=\"darkorange\", s=5, label=\"LOO-CV\")\n",
    "plt.plot(span_vec, loo, color=\"orange\", alpha=1, linestyle=\"dotted\")\n",
    "plt.scatter(span_vec, gcv, color=\"blue\", s=5, label=\"GCV\")\n",
    "plt.plot(span_vec, gcv, color=\"lightblue\", alpha=0.75, linestyle=\"--\")\n",
    "plt.xlabel(\"Span\")\n",
    "plt.ylabel(\"CV Error\")\n",
    "plt.title(\"Span vs CV Error\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset and choice of span values, the best span value selected by LOOCV and GCV is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select lowest span value\n",
    "span_loocv = span_vec[np.argmin(loo)]\n",
    "span_gcv = span_vec[np.argmin(gcv)]\n",
    "\n",
    "print(f\"Span by LOO-CV: {span_loocv}\")\n",
    "print(f\"   Span by GCV: {span_gcv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true curve is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(12 * (x + 0.2)) / (x + 0.2)\n",
    "\n",
    "fx = np.linspace(min(data_part1[\"x\"]), max(data_part1[\"x\"]), 1001)\n",
    "fy = f(fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare the LOESS curve with LOO-CV and GCV optimized span to the true curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_loess = loess(data_part1[\"x\"], data_part1[\"y\"], span=span_loocv).predict(fx).values\n",
    "\n",
    "sns.set()\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "plt.scatter(data_part1[\"x\"], data_part1[\"y\"], color=\"red\", s=6)\n",
    "plt.plot(fx, fy, color=\"gray\", linewidth=1, label=\"True Function\")\n",
    "plt.plot(fx, y_loess, color=\"blue\", linewidth=1, linestyle=\"--\", label=\"LOESS Fit\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following imports are specific to Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "from scipy.interpolate import splev\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we use the Sales_Transactions_Dataset_Weekly dataset from the UCI Machine Learning Repository. After reading the dataset file, we select the time series data and center the time series data by its row means, resulting in $\\textbf{X}_{811 \\times 52}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://archive.ics.uci.edu/dataset/396/sales+transactions+dataset+weekly\n",
    "X = pd.read_csv(\"Sales_Transactions_Dataset_Weekly.csv\",\n",
    "                         index_col=0, usecols=range(53))\n",
    "# Normalize each time series, i.e., normalize each row by its mean\n",
    "X = X.sub(X.mean(axis=1), axis=0).to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series features are simply a vector of indeces corresponding to the weeks of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(start=1, stop=53)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a Python implementation of R's `splines::ns` is provided. It will be used to generate a natural cubic spline basis function matrix. It was copied from [the course website](https://liangfgithub.github.io/Python_W5_RegressionSpline.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://liangfgithub.github.io/Python_W5_RegressionSpline.html\n",
    "# converted from R's ns()\n",
    "def ns(x, df=None, knots=None, boundary_knots=None, include_intercept=False):\n",
    "    degree = 3\n",
    "    \n",
    "    if boundary_knots is None:\n",
    "        boundary_knots = [np.min(x), np.max(x)]\n",
    "    else:\n",
    "        boundary_knots = np.sort(boundary_knots).tolist()\n",
    "\n",
    "    oleft = x < boundary_knots[0]\n",
    "    oright = x > boundary_knots[1]\n",
    "    outside = oleft | oright\n",
    "    inside = ~outside\n",
    "\n",
    "    if df is not None:\n",
    "        nIknots = df - 1 - include_intercept\n",
    "        if nIknots < 0:\n",
    "            nIknots = 0\n",
    "            \n",
    "        if nIknots > 0:\n",
    "            knots = np.linspace(0, 1, num=nIknots + 2)[1:-1]\n",
    "            knots = np.quantile(x[~outside], knots)\n",
    "\n",
    "    Aknots = np.sort(np.concatenate((boundary_knots * 4, knots)))\n",
    "    n_bases = len(Aknots) - (degree + 1)\n",
    "\n",
    "    if any(outside):\n",
    "        basis = np.empty((x.shape[0], n_bases), dtype=float)\n",
    "        e = 1 / 4 # in theory anything in (0, 1); was (implicitly) 0 in R <= 3.2.2\n",
    "\n",
    "        if any(oleft):\n",
    "            k_pivot = boundary_knots[0]\n",
    "            xl = x[oleft] - k_pivot\n",
    "            xl = np.c_[np.ones(xl.shape[0]), xl]\n",
    "\n",
    "            # equivalent to splineDesign(Aknots, rep(k.pivot, ord), ord, derivs)\n",
    "            tt = np.empty((xl.shape[1], n_bases), dtype=float)\n",
    "            for j in range(xl.shape[1]):\n",
    "                for i in range(n_bases):\n",
    "                    coefs = np.zeros((n_bases,))\n",
    "                    coefs[i] = 1\n",
    "                    tt[j, i] = splev(k_pivot, (Aknots, coefs, degree), der=j)\n",
    "\n",
    "            basis[oleft, :] = xl @ tt\n",
    "\n",
    "        if any(oright):\n",
    "            k_pivot = boundary_knots[1]\n",
    "            xr = x[oright] - k_pivot\n",
    "            xr = np.c_[np.ones(xr.shape[0]), xr]\n",
    "\n",
    "            tt = np.empty((xr.shape[1], n_bases), dtype=float)\n",
    "            for j in range(xr.shape[1]):\n",
    "                for i in range(n_bases):\n",
    "                    coefs = np.zeros((n_bases,))\n",
    "                    coefs[i] = 1\n",
    "                    tt[j, i] = splev(k_pivot, (Aknots, coefs, degree), der=j)\n",
    "                    \n",
    "            basis[oright, :] = xr @ tt\n",
    "        \n",
    "        if any(inside):\n",
    "            xi = x[inside]\n",
    "            tt = np.empty((len(xi), n_bases), dtype=float)\n",
    "            for i in range(n_bases):\n",
    "                coefs = np.zeros((n_bases,))\n",
    "                coefs[i] = 1\n",
    "                tt[:, i] = splev(xi, (Aknots, coefs, degree))\n",
    "\n",
    "            basis[inside, :] = tt\n",
    "    else:\n",
    "        basis = np.empty((x.shape[0], n_bases), dtype=float)\n",
    "        for i in range(n_bases):\n",
    "            coefs = np.zeros((n_bases,))\n",
    "            coefs[i] = 1\n",
    "            basis[:, i] = splev(x, (Aknots, coefs, degree))\n",
    "\n",
    "    const = np.empty((2, n_bases), dtype=float)\n",
    "    for i in range(n_bases):\n",
    "        coefs = np.zeros((n_bases,))\n",
    "        coefs[i] = 1\n",
    "        const[:, i] = splev(boundary_knots, (Aknots, coefs, degree), der=2)\n",
    "\n",
    "    if include_intercept is False:\n",
    "        basis = basis[:, 1:]\n",
    "        const = const[:, 1:]\n",
    "\n",
    "    qr_const = np.linalg.qr(const.T, mode='complete')[0]\n",
    "    basis = (qr_const.T @ basis.T).T[:, 2:]\n",
    "\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `ns` to generate the basis function matrix $\\textbf{F}_{52 \\times 9}$ and remove the intercept by centering its columns by their means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_mat = ns(t, df=9, include_intercept=False)\n",
    "F_mat = F_mat - F_mat.mean(axis=0)[np.newaxis, :]\n",
    "F_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $\\textbf{F}$ and $\\textbf{X}$, we can calculate a matrix of spline coefficients for every obbservation, $\\textbf{B}_{811 \\times 9}$. This is found by the following formula, which is implemented below.\n",
    "\n",
    "$$\n",
    "\\textbf{B}^{\\top} = (\\textbf{F}^{\\top} \\ \\textbf{F})^{-1} \\ \\textbf{F}^{\\top} \\textbf{X}^{\\top}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = inv(F_mat.T @ F_mat) @ F_mat.T @ X.T\n",
    "B = B.T\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using Matrix $\\textbf{B}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 6\n",
    "n_row = 2\n",
    "n_col = 3\n",
    "\n",
    "km_B = KMeans(n_clusters=n_clusters, n_init=10).fit(B)\n",
    "centers_B = F_mat @ km_B.cluster_centers_.T\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, dpi=300,\n",
    "                        sharex=\"all\", sharey=\"all\")\n",
    "for i in range(n_row):\n",
    "    for j in range(n_col):\n",
    "        series = X[km_B.labels_ == i * n_col + j, :]\n",
    "        for k in range(series.shape[0]):\n",
    "            axs[i, j].plot(t, series[k], color=\"darkgrey\", linewidth=0.75)\n",
    "        axs[i, j].plot(t, centers_B[:, i * n_col + j], color=\"red\", linewidth=0.75)\n",
    "        axs[i, j].set_xlim([1, 52])\n",
    "        axs[i, j].set_ylim([-30, 30])\n",
    "        axs[i, j].set_xticks(range(0, 52, 10))\n",
    "        axs[i, j].set_yticks(np.linspace(-30, 30, 7))\n",
    "        axs[i, j].set_xlabel(\"Weeks\")\n",
    "        axs[i, j].set_ylabel(\"Weekly Sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using Matrix $\\textbf{B}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_X = KMeans(n_clusters=n_clusters, n_init=10).fit(X)\n",
    "centers_X = km_X.cluster_centers_.T\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, dpi=300,\n",
    "                        sharex=\"all\", sharey=\"all\")\n",
    "for i in range(n_row):\n",
    "    for j in range(n_col):\n",
    "        series = X[km_X.labels_ == i * n_col + j, :]\n",
    "        for k in range(series.shape[0]):\n",
    "            axs[i, j].plot(t, series[k], color=\"darkgrey\", linewidth=0.75)\n",
    "        axs[i, j].plot(t, centers_X[:, i * n_col + j], color=\"red\", linewidth=0.75)\n",
    "        axs[i, j].set_xlim([1, 52])\n",
    "        axs[i, j].set_ylim([-30, 30])\n",
    "        axs[i, j].set_xticks(range(0, 52, 10))\n",
    "        axs[i, j].set_yticks(np.linspace(-30, 30, 7))\n",
    "        axs[i, j].set_xlabel(\"Weeks\")\n",
    "        axs[i, j].set_ylabel(\"Weekly Sales\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
