{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment 5: Support Vector Machine Classifier\n",
    "\n",
    "CS 598 Practical Statistical Learning\n",
    "\n",
    "2023-11-27\n",
    "\n",
    "UIUC Fall 2023\n",
    "\n",
    "**Authors**\n",
    "* Ryan Fogle\n",
    "    - rsfogle2@illinois.edu\n",
    "    - UIN: 652628818\n",
    "* Sean Enright\n",
    "    - seanre2@illinois.edu\n",
    "    - UIN: 661791377\n",
    "\n",
    "**Contributions**\n",
    "\n",
    "Ryan provided the initial implementation of the Pegasos algorithm, as well as the initial data cleaning, confusion matrices and test results.\n",
    "\n",
    "Sean refactored the Pegasos algorithm implementation to vectorize operations, cleaned up the relabeling of data and added markdown to explain steps of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment, we implement a Support Vector Machine (SVM) classifier using the Pegasos (Primal Estimated sub-GrAdient SOlver for SVM) algorithm. The Pegasos algorithm itself optimizes SVM parameters using stochastic gradient descent (SGD).\n",
    "\n",
    "To validate our implementation, we classify two digits of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pegasos Algorithm\n",
    "\n",
    "The learning problem for a SVM can be stated as the following minimization problem:\n",
    "$$\n",
    "\\min_{\\beta, \\alpha}\n",
    "\\frac{\\lambda}{2} \\lVert \\beta \\rVert^2\n",
    "+ \\frac{1}{n} \\sum_{i=1}^{n} \\left [ 1 - y(x^t \\beta + \\alpha) \\right ]_{+}\n",
    "$$\n",
    "\n",
    "In the Pegasos algorithm, this objective function $J$ is iteratively approximated with samples of the training set observations as follows.\n",
    "\n",
    "$$\n",
    "J_i(\\beta, \\alpha) = \n",
    "\\frac{\\lambda}{2} \\lVert \\beta \\rVert^2\n",
    "+ \\frac{1}{n} \\sum_{i=1}^{n} \\left [ 1 - y_i(x_i^t \\beta + \\alpha) \\right ]_{+}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the intercept and $\\beta$ is the p-dimensional coefficient vector.\n",
    "\n",
    "These two parameters are updated iteratively by using their subgradients to approach a local optimum. These subgradients are\n",
    "\n",
    "$$\n",
    "\\Delta_t =\n",
    "\\begin{cases}\n",
    "    \\lambda \\beta_t - y_i x_i & \\text{if} y_i(x_i^t \\beta_t + \\alpha_t) < 1 \\\\\n",
    "    \\lambda \\beta_t           & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_t =\n",
    "\\begin{cases}\n",
    "    -y_i & \\text{if} y_i(x_i^t \\beta_t + \\alpha_t) < 1 \\\\\n",
    "    0    & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\Delta_t$ and $\\delta_t$ are the subgradients at iteration $t$ with respect to $\\beta$ and $\\alpha$, respectively.\n",
    "\n",
    "The Pegasos algorithm can be summarized as follows:\n",
    "\n",
    "1. initialize $\\beta = 0_{p \\times 1}$, $\\alpha_1 = 0$, and $t=0$\n",
    "2. for epoch = $1, 2, ..., T$, do\n",
    "    * for $i = 1, 2, â€¦, n$, do\n",
    "        * $t = t + 1$\n",
    "        * $\\eta_t = \\frac{1}{t \\, \\lambda}$\n",
    "        * $\\beta_{t+1} \\Leftarrow \\beta_t - \\eta_t \\, \\Delta_t$\n",
    "        * $\\alpha_{t+1} \\Leftarrow \\alpha_t - \\eta_t \\, \\delta_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(x, y, epochs=20, lam=1):\n",
    "    \"\"\"Perform the Pegasos algorithm to estimate SVM parameters\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): n x p training data\n",
    "        y (np.ndarray): Labels\n",
    "        epochs (int, optional): Number of epochs to execute algorithm. Defaults to 20.\n",
    "        lam (int, optional): Learning rate hyperparameter. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray, int): Updated estimates for SVM parameters beta and alpha, respectively\n",
    "    \"\"\"\n",
    "\n",
    "    # Intialize parameters\n",
    "    beta  = np.zeros(x.shape[1])\n",
    "    alpha = 0\n",
    "    t     = 1\n",
    "    n     = y.shape[0]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle data\n",
    "        inds = np.arange(n)\n",
    "        np.random.shuffle(inds)\n",
    "        x = x[inds]\n",
    "        y = y[inds]\n",
    "\n",
    "        # eta is vectorized, using t values that increase for each observation\n",
    "        eta = (1 / (lam * np.arange(t, t + n))).reshape(-1, 1)\n",
    "\n",
    "        # in_margin: support vectors\n",
    "        in_margin = (y * np.squeeze(x @ beta.reshape(-1, 1) + alpha)) < 1\n",
    "\n",
    "        # Beta (big delta) subgradient:\n",
    "        beta_grad = np.empty(x.shape)\n",
    "        beta_grad[in_margin] = lam * beta - y[in_margin].reshape(-1, 1) * x[in_margin, :]\n",
    "        beta_grad[~in_margin] = lam * beta\n",
    "        beta_grad = (eta * beta_grad).sum(axis=0)\n",
    "        \n",
    "        # Alpha (little delta) subgradient\n",
    "        alpha_grad = np.empty(y.shape)\n",
    "        alpha_grad[in_margin]  = -y[in_margin]\n",
    "        alpha_grad[~in_margin] = 0\n",
    "        alpha_grad = (eta * alpha_grad).sum(axis=0)[0]\n",
    "\n",
    "        # Update beta, alpha and t\n",
    "        beta -= beta_grad\n",
    "        alpha -= alpha_grad\n",
    "        t += n\n",
    "    return beta, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "To train a SVM and validate its classification ability, a subset of the MNIST dataset is used. 200 training samples and 600 test samples are used. Only observations with the labels \"5\" and \"6\" are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(3434)\n",
    "\n",
    "# Read in data\n",
    "train = pd.read_csv('coding5_train.csv')\n",
    "test = pd.read_csv('coding5_test.csv')\n",
    "\n",
    "# Create Data matrixes\n",
    "train_x = train[train.columns[:-1]].copy().values\n",
    "train_y = train['Y'].copy().values\n",
    "test_x = test[test.columns[:-1]].copy().values\n",
    "test_y = test['Y'].copy().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our SVM expects the labels to be either $-1$ or $1$, so we relabel the MNIST data accordingly:\n",
    "* $5$ (`class_a`) is relabeled as $-1$\n",
    "* $6$ (`class_b`) is relabled as $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_a = 5\n",
    "class_b = 6\n",
    "train_y_relabeled = np.where(train_y == class_a, -1, 1)\n",
    "test_y_relabeled  = np.where(test_y  == class_b, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "To validate our SVM implementation, we present confusion tables for the training and test datasets, as well as test error.\n",
    "\n",
    "### Training\n",
    "\n",
    "The SVM is trained on the test partition for $T=20$ epochs with $\\lambda=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 20\n",
    "lam       = 1  # lambda hyperparameter\n",
    "\n",
    "beta, alpha = pegasos(x=train_x, y=train_y_relabeled, epochs=num_epoch, lam=lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Here we generate predictions $\\hat{y}$ by\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{cases}\n",
    "0 &  x^t \\beta + \\alpha < 0 \\\\\n",
    "1 &  x^t \\beta + \\alpha > 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "and relabel the predictions as label \"5\" or \"6\" accordingly.\n",
    "\n",
    "Predictions are made for the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train_y_pred = train_x @ beta.T + alpha\n",
    "train_y_pred = np.where(train_y_pred < 0, class_a, class_b)\n",
    "\n",
    "# Test dataset\n",
    "test_y_pred = test_x @ beta.T + alpha\n",
    "test_y_pred = np.where(test_y_pred < 0, class_a, class_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices\n",
    "\n",
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ConfusionMatrixDisplay(confusion_matrix(train_y, train_y_pred))\n",
    "fig.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ConfusionMatrixDisplay(confusion_matrix(test_y, test_y_pred))\n",
    "fig.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(test_y, test_y_pred)\n",
    "print(f'Test Error: {(1 - acc) * 100:.2f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
