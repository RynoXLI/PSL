{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment 5: Support Vector Machine Classifier\n",
    "\n",
    "CS 598 Practical Statistical Learning\n",
    "\n",
    "2023-11-27\n",
    "\n",
    "UIUC Fall 2023\n",
    "\n",
    "**Authors**\n",
    "* Ryan Fogle\n",
    "    - rsfogle2@illinois.edu\n",
    "    - UIN: 652628818\n",
    "* Sean Enright\n",
    "    - seanre2@illinois.edu\n",
    "    - UIN: 661791377\n",
    "\n",
    "**Contributions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment, we implement a Support Vector Machine (SVM) classifier using the Pegasos (Primal Estimated sub-GrAdient SOlver for SVM) algorithm. The Pegasos algorithm itself optimizes SVM parameters using stochastic gradient descent (SGD).\n",
    "\n",
    "To validate our implementation, we classify two digits of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pegasos Algorithm\n",
    "\n",
    "The learning problem for a SVM can be stated as the following minimization problem:\n",
    "$$\n",
    "\\min_{\\beta, \\alpha}\n",
    "\\frac{\\lambda}{2} \\lVert \\beta \\rVert^2\n",
    "+ \\frac{1}{n} \\sum_{i=1}^{n} \\left [ 1 - y(x^t \\beta + \\alpha) \\right ]_{+}\n",
    "$$\n",
    "\n",
    "In the Pegasos algorithm, this objective function $J$ is iteratively approximated with samples of the training set observations as follows.\n",
    "\n",
    "$$\n",
    "J_i(\\beta, \\alpha) = \n",
    "\\frac{\\lambda}{2} \\lVert \\beta \\rVert^2\n",
    "+ \\frac{1}{n} \\sum_{i=1}^{n} \\left [ 1 - y_i(x_i^t \\beta + \\alpha) \\right ]_{+}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the intercept and $\\beta$ is the p-dimensional coefficient vector.\n",
    "\n",
    "These two parameters are updated iteratively by using their subgradients to approach a local optimum. These subgradients are\n",
    "\n",
    "$$\n",
    "\\Delta_t =\n",
    "\\begin{cases}\n",
    "    \\lambda \\beta_t - y_i x_i & \\text{if} y_i(x_i^t \\beta_t + \\alpha_t) < 1 \\\\\n",
    "    \\lambda \\beta_t           & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_t =\n",
    "\\begin{cases}\n",
    "    -y_i & \\text{if} y_i(x_i^t \\beta_t + \\alpha_t) < 1 \\\\\n",
    "    0    & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\Delta_t$ and $\\delta_t$ are the subgradients at iteration $t$ with respect to $\\beta$ and $\\alpha$, respectively.\n",
    "\n",
    "The Pegasos algorithm can be summarized as follows:\n",
    "\n",
    "1. initialize $\\beta = 0_{p \\times 1}$, $\\alpha_1 = 0$, and $t=0$\n",
    "2. for epoch = $1, 2, ..., T$, do\n",
    "    * for $i = 1, 2, â€¦, n$, do\n",
    "        * $t = t + 1$\n",
    "        * $\\eta_t = \\frac{1}{t \\, \\lambda}$\n",
    "        * $\\beta_{t+1} \\Leftarrow \\beta_t - \\eta_t \\, \\Delta_t$\n",
    "        * $\\alpha_{t+1} \\Leftarrow \\alpha_t - \\eta_t \\, \\delta_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(x, y, epochs=20, lam=1):\n",
    "\n",
    "    # Intialize parameters\n",
    "    beta  = np.zeros(x.shape[1])\n",
    "    alpha = 0\n",
    "    t     = 1\n",
    "    n     = y.shape[0]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle data\n",
    "        inds = np.arange(n)\n",
    "        np.random.shuffle(inds)\n",
    "        x = x[inds]\n",
    "        y = y[inds]\n",
    "\n",
    "        # eta is vectorized, using t values that increase for each observation\n",
    "        eta = (1 / (lam * np.arange(t, t + n))).reshape(-1, 1)\n",
    "\n",
    "        # in_margin: support vectors\n",
    "        in_margin = (y * np.squeeze(x @ beta.reshape(-1, 1) + alpha)) < 1\n",
    "\n",
    "        # Beta (big delta) subgradient:\n",
    "        beta_grad = np.empty(x.shape)\n",
    "        beta_grad[in_margin] = lam * beta - \\\n",
    "                               y[in_margin].reshape(-1, 1) * \\\n",
    "                               x[in_margin, :]\n",
    "        beta_grad[~in_margin] = lam * beta\n",
    "        beta_grad = (eta * beta_grad).sum(axis=0)\n",
    "        \n",
    "        # Alpha (little delta) subgradient\n",
    "        alpha_grad = np.empty(y.shape)\n",
    "        alpha_grad[in_margin]  = -y[in_margin]\n",
    "        alpha_grad[~in_margin] = 0\n",
    "        alpha_grad = (eta * alpha_grad).sum(axis=0)[0]\n",
    "\n",
    "        # Update beta, alpha and t\n",
    "        beta -= beta_grad\n",
    "        alpha -= alpha_grad\n",
    "        t += n\n",
    "    return beta, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "To train a SVM and validate its classification ability, a subset of the MNIST dataset is used. 200 training samples and 600 test samples are used. Only observations with the labels \"5\" and \"6\" are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(3434)\n",
    "\n",
    "# Read in data\n",
    "train = pd.read_csv('coding5_train.csv')\n",
    "test = pd.read_csv('coding5_test.csv')\n",
    "\n",
    "# Create Data matrixes\n",
    "X_train = train[train.columns[:-1]].copy().values\n",
    "Y_train = train['Y'].copy().values\n",
    "X_test = test[test.columns[:-1]].copy().values\n",
    "Y_test = test['Y'].copy().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our SVM expects the labels to be either $-1$ or $1$, so we relabel $5$ as $-1$, and $6$ as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set one class to be -1, the other to 1\n",
    "# in this case when Y == 5, we set it to -1\n",
    "# when Y == 6, we set it to 1. \n",
    "y_train = np.ones(Y_train.shape[0])\n",
    "y_train[Y_train == Y_train.min()] = -1\n",
    "\n",
    "y_test = np.ones(Y_test.shape[0])\n",
    "y_test[Y_test == Y_test.min()] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "To validate our SVM implementation, we present confusion tables for the training and test datasets, as well as test error.\n",
    "\n",
    "## Predictions\n",
    "Here we generate predictions $\\hat{y}$ by\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{cases}\n",
    "0 &  x^t \\beta + \\alpha < 0 \\\\\n",
    "1 &  x^t \\beta + \\alpha > 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "and relabel the predictions as label \"5\" or \"6\" accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, alpha = pegasos(X_train, y_train)\n",
    "Y_pred = (X_test @ beta + alpha).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices\n",
    "\n",
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ConfusionMatrixDisplay(confusion_matrix(Y_test == Y_test.max(), Y_pred > 0))\n",
    "fig.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(Y_test == Y_test.max(), Y_pred.reshape(-1) > 0)\n",
    "print(f'Accuracy: {acc:.2f}')\n",
    "print(f'Test Error: {1 - acc:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
