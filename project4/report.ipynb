{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Movie Recommender System\n",
    "\n",
    "CS 598 Practical Statistical Learning\n",
    "\n",
    "2023-12-10\n",
    "\n",
    "UIUC Fall 2023\n",
    "\n",
    "**Authors**\n",
    "* Ryan Fogle\n",
    "    - rsfogle2@illinois.edu\n",
    "    - UIN: 652628818\n",
    "* Sean Enright\n",
    "    - seanre2@illinois.edu\n",
    "    - UIN: 661791377\n",
    "\n",
    "**Contributions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dir = Path('.') / 'ml-1m' / 'ml-1m' \n",
    "ratings = pd.read_csv(movie_dir / 'ratings.dat', sep='::', engine = 'python', header=None)\n",
    "ratings.columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "movies = pd.read_csv(movie_dir / 'movies.dat', sep='::', engine = 'python',\n",
    "                     encoding=\"ISO-8859-1\", header = None)\n",
    "movies.columns = ['MovieID', 'Title', 'Genres']\n",
    "users = pd.read_csv(movie_dir / 'users.dat', sep='::', engine='python', header=None)\n",
    "users.columns = ['UserID', 'Gender', 'Age', 'Occupation', 'Zipcode']\n",
    "\n",
    "# Create new entry for each genre in a movie, join movie and ratings together. \n",
    "movies['Genres'] = movies['Genres'].str.split('|')\n",
    "df = movies.explode('Genres')\n",
    "df = df.merge(ratings, on=['MovieID'], how='left')\n",
    "df.rename(columns={'Genres': 'Genre'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MovieID -> Title map for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_title_map = dict(zip(movies['MovieID'], movies['Title']))\n",
    "list(mov_title_map.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System I: Recommendation Based on Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General idea: Use Bayseian probabilty to calcuate new ratings based upon additional prior assumptions, and then rank movies by this new rating to select the top 5 per genre.\n",
    "\n",
    "This algorthm is based upon this stack overflow post:\n",
    "https://stackoverflow.com/questions/2495509/how-to-balance-number-of-ratings-versus-the-ratings-themselves\n",
    "\n",
    "$$\n",
    "\\tilde{R} = \\frac{\\bar{w} \\bar{r} + \\sum_{i=1}^{n}{r_i}}{\\bar{w} + n}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\tilde{R}$ is the new rating\n",
    "- $\\bar{w}$ is the predefined number of ratings (weight) to include in our prior assumption\n",
    "- $\\bar{r}$ is the predefined average rating to include in our prior assumption\n",
    "- $n$ is the number of ratings\n",
    "- $r_i$ is the rating for a given entry.\n",
    "\n",
    "**Interpretation**:\n",
    "\n",
    "Consider $\\bar{w}$ to be the average number of ratings for a given genre, and $\\bar{r}$ to be the number of times to consider that rating for a given genre. We first assume the rating of a movie to be defined as $\\frac{\\bar{w} \\bar{r}}{\\bar{w}}$ when $n=0$, then slightly update the estimate for each new given rating. \n",
    "\n",
    "In our implementation we defined $\\bar{w}$ to be the median genre rating from the average movie ratings in that genre. We also define $\\bar{r}$ to be the genre's 25th percentile count (of ratings per movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by Genre and Movie, this will be used to find median ratings and percentile counts for our prior\n",
    "gb = df.groupby(['Genre', 'MovieID'])\n",
    "\n",
    "# Median Genre ratings of Average Movie ratings\n",
    "median_ratings = gb['Rating'].mean().reset_index().groupby('Genre')['Rating'].median().reset_index()\n",
    "median_ratings = dict(zip(median_ratings['Genre'], median_ratings['Rating']))\n",
    "median_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab 25th Percentile of count by genre\n",
    "quantile_count = gb['Timestamp'].count().reset_index().groupby('Genre')['Timestamp'].quantile(0.25).reset_index()\n",
    "quantile_count.columns = ['Genre', 'Count']\n",
    "quantile_count = dict(zip(quantile_count['Genre'], quantile_count['Count']))\n",
    "quantile_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_ratings = []\n",
    "for (genre, movie_id), movie in gb:\n",
    "    n = movie.shape[0]\n",
    "    w = quantile_count[genre]\n",
    "    r = median_ratings[genre] \n",
    "    weighted_rating = (r * w + movie['Rating'].sum()) / (w + n)\n",
    "    weighted_ratings.append((genre, movie_id, mov_title_map[movie_id], weighted_rating, movie['Rating'].sum() / n, n))\n",
    "\n",
    "w_df = pd.DataFrame(weighted_ratings, columns=['Genre', 'MovieID', 'Title', 'WeightedRating', 'AverageRating', '# of Ratings'])\n",
    "w_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort ratings by WeightedRating, group by genre and grab the first five occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysI_recs = w_df.sort_values('WeightedRating', ascending=False).groupby('Genre').head(n=10).sort_values(['Genre', 'WeightedRating'], ascending=[True, False])\n",
    "sysI_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output System I recommends for the dashboard to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysI_recs.to_csv('sysI_recs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System II: Recommendation Based on IBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_mov_df = pd.read_csv('Rmat.csv')\n",
    "usr_mov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
