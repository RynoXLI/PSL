{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Movie Recommender System\n",
    "\n",
    "CS 598 Practical Statistical Learning\n",
    "\n",
    "2023-12-10\n",
    "\n",
    "UIUC Fall 2023\n",
    "\n",
    "**Authors**\n",
    "* Ryan Fogle\n",
    "    - rsfogle2@illinois.edu\n",
    "    - UIN: 652628818\n",
    "* Sean Enright\n",
    "    - seanre2@illinois.edu\n",
    "    - UIN: 661791377\n",
    "\n",
    "**Contributions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dir = Path('.') / 'ml-1m' / 'ml-1m' \n",
    "ratings = pd.read_csv(movie_dir / 'ratings.dat', sep='::', engine = 'python', header=None)\n",
    "ratings.columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "movies = pd.read_csv(movie_dir / 'movies.dat', sep='::', engine = 'python',\n",
    "                     encoding=\"ISO-8859-1\", header = None)\n",
    "movies.columns = ['MovieID', 'Title', 'Genres']\n",
    "users = pd.read_csv(movie_dir / 'users.dat', sep='::', engine='python', header=None)\n",
    "users.columns = ['UserID', 'Gender', 'Age', 'Occupation', 'Zipcode']\n",
    "\n",
    "# Create new entry for each genre in a movie, join movie and ratings together. \n",
    "movies['Genres'] = movies['Genres'].str.split('|')\n",
    "df = movies.explode('Genres')\n",
    "df = df.merge(ratings, on=['MovieID'], how='left')\n",
    "df.rename(columns={'Genres': 'Genre'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MovieID -> Title map for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_title_map = dict(zip(movies['MovieID'], movies['Title']))\n",
    "list(mov_title_map.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System I: Recommendation Based on Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General idea: Use Bayseian probabilty to calcuate new ratings based upon additional prior assumptions, and then rank movies by this new rating to select the top 5 per genre.\n",
    "\n",
    "This algorthm is based upon this stack overflow post:\n",
    "https://stackoverflow.com/questions/2495509/how-to-balance-number-of-ratings-versus-the-ratings-themselves\n",
    "\n",
    "$$\n",
    "\\tilde{R} = \\frac{\\bar{w} \\bar{r} + \\sum_{i=1}^{n}{r_i}}{\\bar{w} + n}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\tilde{R}$ is the new rating\n",
    "- $\\bar{w}$ is the predefined number of ratings (weight) to include in our prior assumption\n",
    "- $\\bar{r}$ is the predefined average rating to include in our prior assumption\n",
    "- $n$ is the number of ratings\n",
    "- $r_i$ is the rating for a given entry.\n",
    "\n",
    "**Interpretation**:\n",
    "\n",
    "Consider $\\bar{w}$ to be the average number of ratings for a given genre, and $\\bar{r}$ to be the number of times to consider that rating for a given genre. We first assume the rating of a movie to be defined as $\\frac{\\bar{w} \\bar{r}}{\\bar{w}}$ when $n=0$, then slightly update the estimate for each new given rating. \n",
    "\n",
    "In our implementation we defined $\\bar{w}$ to be the median genre rating from the average movie ratings in that genre. We also define $\\bar{r}$ to be the genre's 25th percentile count (of ratings per movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by Genre and Movie, this will be used to find median ratings and percentile counts for our prior\n",
    "gb = df.groupby(['Genre', 'MovieID'])\n",
    "\n",
    "# Median Genre ratings of Average Movie ratings\n",
    "median_ratings = gb['Rating'].mean().reset_index().groupby('Genre')['Rating'].median().reset_index()\n",
    "median_ratings = dict(zip(median_ratings['Genre'], median_ratings['Rating']))\n",
    "median_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab 25th Percentile of count by genre\n",
    "quantile_count = gb['Timestamp'].count().reset_index().groupby('Genre')['Timestamp'].quantile(0.25).reset_index()\n",
    "quantile_count.columns = ['Genre', 'Count']\n",
    "quantile_count = dict(zip(quantile_count['Genre'], quantile_count['Count']))\n",
    "quantile_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_ratings = []\n",
    "for (genre, movie_id), movie in gb:\n",
    "    n = movie.shape[0]\n",
    "    w = quantile_count[genre]\n",
    "    r = median_ratings[genre] \n",
    "    weighted_rating = (r * w + movie['Rating'].sum()) / (w + n)\n",
    "    weighted_ratings.append((genre, movie_id, mov_title_map[movie_id], weighted_rating, movie['Rating'].sum() / n, n))\n",
    "\n",
    "w_df = pd.DataFrame(weighted_ratings, columns=['Genre', 'MovieID', 'Title', 'WeightedRating', 'AverageRating', '# of Ratings'])\n",
    "w_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort ratings by WeightedRating, group by genre and grab the first five occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysI_recs = w_df.sort_values('WeightedRating', ascending=False).groupby('Genre').head(n=10).sort_values(['Genre', 'WeightedRating'], ascending=[True, False])\n",
    "sysI_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output System I recommends for the dashboard to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysI_recs.to_csv('sysI_recs.csv', index=False)\n",
    "w_df.to_csv('sysI_recs_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System II: Recommendation Based on IBCF\n",
    "\n",
    "### Similarity Matrix Construction\n",
    "\n",
    "To construct the similarity matrix, we require user ratings for various items. The input rating matrix is $R_{a \\times i}$, where $a$ is the number of users who have reviewed one or more movie, and $i$ is the number of movies.\n",
    "\n",
    "In the case of our dataset, there are 6040 users and 3706 movies, so $R$ is of shape $6040 \\times 3706$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mov_df = pd.read_csv('Rmat.csv')\n",
    "user_mov_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of Ratings Matrix\n",
    "We normalize the rating matrix by subtracting the row means from each row, ignoring `NA` entries. This addresses the variation in each user's average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mov_df_norm = user_mov_df.sub(user_mov_df.mean(axis=1, skipna=True), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "We seek to compute the similarity between movies (items). We select centered cosine similarity as our measure of similarity. Having normalized our ratings matrix by each user's average rating, the next step is computation of similarity.\n",
    "\n",
    "Our implementation of the cosine similarity between items is described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cosine_similarity(x, min_cardinality=3):    \n",
    "    # Prepare symmetric result matrix\n",
    "    s = np.empty((x.shape[1], x.shape[1]))\n",
    "    s[:] = np.nan\n",
    "\n",
    "    # Calculate similarity for upper trianglular matrix\n",
    "    for i in tqdm(range(0, x.shape[1] - 1)):\n",
    "        i_valid = ~np.isnan(x[:, i])\n",
    "        for j in range(i + 1, x.shape[1]):\n",
    "            j_valid = ~np.isnan(x[:, j])\n",
    "            row_mask = np.logical_and(i_valid, j_valid)\n",
    "            if row_mask.sum() >= min_cardinality:\n",
    "                r_li = x[row_mask, i]\n",
    "                r_lj = x[row_mask, j]\n",
    "                s[i, j] = (np.dot(r_li, r_lj)\n",
    "                           / (np.sqrt(np.power(r_li, 2).sum()) \n",
    "                              * np.sqrt(np.power(r_lj, 2).sum())))\n",
    "    s = 0.5 + s / 2\n",
    "\n",
    "    # Transpose upper triangular matrix to form lower\n",
    "    lower_idx = np.tril_indices(x.shape[1])\n",
    "    s[lower_idx] = s.T[lower_idx]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this function to our centered ratings matrix, producing a symmetric similarity matrix $S_{i \\times i}$.\n",
    "\n",
    "We extract and re-wrap the column indices to retain the movie IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cardinality = 3\n",
    "\n",
    "s = cosine_similarity(user_mov_df_norm.to_numpy(), min_cardinality=min_cardinality)\n",
    "s = pd.DataFrame(data=s,\n",
    "                 index=user_mov_df_norm.columns,\n",
    "                 columns=user_mov_df_norm.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation of Similarity Matrix Before Filtering\n",
    "\n",
    "In order to validate our similarity matrix and our implementation of centered cosine similarity, we show the pairwise similarity values from the $S$ matrix for the following specified movies:\n",
    "\n",
    "```m1, m10, m100, m1510, m260, m3212```\n",
    "\n",
    "We are validating our results against the values in [Campuswire post #861](https://campuswire.com/c/G06C55090/feed/861)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 7)\n",
    "specified_movies = [\"m1\", \"m10\", \"m100\", \"m1510\", \"m260\", \"m3212\"]\n",
    "s.loc[specified_movies, specified_movies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by Most Similar Movies\n",
    "\n",
    "Next, for each movie, we determine the 30 most similar movies and set all other movies to NA. This allows for a more compact $S$ matrix. For movies that have fewer than 30 similar movies, all available similar movies (i.e., non-`NA`) are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_similar = 30\n",
    "\n",
    "for i in range(s.shape[0]):\n",
    "    row = s.iloc[i, :]\n",
    "    num_selected = min([(~np.isnan(row)).sum(), max_similar, len(row)])\n",
    "    # Find max allowed similarity with NaN vals\n",
    "    max_sim = np.roll(np.sort(row)[::-1],\n",
    "                      -np.count_nonzero(np.isnan(row)))[num_selected - 1]\n",
    "    na_mask = row < max_sim\n",
    "    s.iloc[i, na_mask] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This filtered similarity matrix is written to file as `similarity.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv(\"similarity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBF\n",
    "\n",
    "#### Implementation of ICBF\n",
    "\n",
    "We calculate IBCF for all non-rated movies and return the 10 highest recommendations.\n",
    "\n",
    "In the case of tie breaks, movies are recommended by `WeightedRating` from System I, then `movieID` for further tie breaks in descending order, so the highest `WeightedRating`, `movieID` is included first, followed by the second-highest, etc.\n",
    "\n",
    "If fewer than 10 recommendations are calculated, we fill the missing recommendations with the highest-rated movies in the user's most watched genres. We use the `WeightedRatings` from the SystemI implementation for our definition of \"highest-rated movies\". In the case of multiple highest-rated movies, we pick the genre of the lowest `movieID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myIBCF(s, newuser, sysI, num_recs=10):\n",
    "\n",
    "    recs = newuser.copy(deep=True)\n",
    "    recs.iloc[:] = np.nan\n",
    "\n",
    "    i_in_w = ~np.isnan(newuser)\n",
    "    # Compute IBCF for non-rated movies\n",
    "    for l in np.arange(newuser.shape[0])[np.isnan(newuser)]:\n",
    "        s_li = s.iloc[l, :]\n",
    "        i_in_sl = ~np.isnan(s_li)\n",
    "        col_mask = np.logical_and(i_in_sl, i_in_w)\n",
    "        if s_li[col_mask].sum() == 0:\n",
    "            continue\n",
    "        recs.iloc[l] = (\n",
    "            1 / (s_li[col_mask].sum())\n",
    "            * np.dot(s_li[col_mask], newuser[col_mask])\n",
    "        )\n",
    "    recs = recs[~np.isnan(recs)] \n",
    "\n",
    "    # Create mappings needed for ranking\n",
    "    mid_to_rating = dict(zip(sysI['MovieID'], sysI['WeightedRating']))\n",
    "    mid_to_genre = dict(zip(sysI['MovieID'], sysI['Genre']))\n",
    "    #print(f\"# ratings: {np.count_nonzero(~np.isnan(newuser))}\")\n",
    "    #print(f\"   # recs: {recs.shape[0]}\")\n",
    "    if recs.shape[0] >= num_recs:\n",
    "        #print(recs.iloc[recs.argsort().iloc[-num_recs:]])\n",
    "        rec_df = recs.iloc[recs.argsort().iloc[-num_recs:]]\n",
    "\n",
    "        # Find (mid, IBCF value, Weighted Rating from System I) pairs\n",
    "        recnames = [(mid, val, mid_to_rating[int(mid[1:])]) for mid, val in zip(rec_df.index, rec_df.values)]\n",
    "\n",
    "        # Sort by (IBCF value, Weighted rating from System I, then mid) descending\n",
    "        recs = [x[0] for x in sorted(recnames, key=lambda x: (x[1], x[2], int(x[0][1:])))][::-1]\n",
    "        return recs\n",
    "    else:\n",
    "        additional_recs = num_recs - recs.shape[0]\n",
    "\n",
    "        # Run through regular logic\n",
    "        rec_df = recs.iloc[recs.argsort().iloc[-num_recs:]]\n",
    "        mids = [int(mid[1:]) for mid in rec_df.index]\n",
    "        recnames = [(mid, val, mid_to_rating[int(mid[1:])]) for mid, val in zip(rec_df.index, rec_df.values)]\n",
    "        recs = [x[0] for x in sorted(recnames, key=lambda x: (x[1], x[2], int(x[0][1:])))][::-1]\n",
    "\n",
    "        # From the movies rated by the user, find the most watched genre and return top recommendations from it\n",
    "        # If there is a tie for most watched genre, then both are considered. \n",
    "        # Select the top movies by WeightedRating from System I for the given top genre(s). \n",
    "        # Make sure that the movies from the genre are not the same movies the user rated and also not already included from the IBCF recommendations.\n",
    "        rated_movies = newuser[~np.isnan(newuser)]\n",
    "        genre_mids = [int(movie[1:]) for movie in rated_movies.index]\n",
    "        genres = np.unique([mid_to_genre[mid] for mid in genre_mids])\n",
    "        mids.extend(genre_mids)\n",
    "        movie_ids = sysI[sysI['Genre'].isin(genres) & ~sysI['MovieID'].isin(mids)].sort_values(by=['WeightedRating', 'MovieID'], ascending=[False, True])[:additional_recs]['MovieID']\n",
    "        movie_ids = [f'm{mid}' for mid in movie_ids.values]\n",
    "\n",
    "        return recs + movie_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation of `myIBCF`\n",
    "\n",
    "To validate our implementation of `myIBCF`, we show the top 10 recommendations for:\n",
    "* User \"u1181\" from rating matrix $R$\n",
    "* User \"u1351\" from rating matrix $R$\n",
    "* A hypothetical user who rates movie “m1613” with 5 and movie “m1755” with 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_user = user_mov_df.iloc[0, :].copy(deep=True)\n",
    "hypothetical_user.iloc[:] = np.nan\n",
    "hypothetical_user.loc[[\"m1613\", \"m1755\"]] = [5, 4]\n",
    "\n",
    "test_users = [\n",
    "    (\"User u1181\", user_mov_df.loc[\"u1181\", :]),\n",
    "    (\"User u1351\", user_mov_df.loc[\"u1351\", :]),\n",
    "    (\"Hypothetical user\", hypothetical_user)\n",
    "]\n",
    "\n",
    "for username, w in test_users:\n",
    "    print(f\"\\n{username}\\n--{len(username)*'-'}\\n{myIBCF(s, w, w_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for edge-case of less than 10 recommendations given by IBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_user = user_mov_df.iloc[0, :].copy(deep=True)\n",
    "hypothetical_user.iloc[:] = np.nan\n",
    "hypothetical_user.loc[[\"m6\"]] = [5]\n",
    "\n",
    "test_users = [\n",
    "    (\"Hypothetical user\", hypothetical_user)\n",
    "]\n",
    "\n",
    "for username, w in test_users:\n",
    "    print(f\"\\n{username}\\n--{len(username)*'-'}\\n{myIBCF(s, w, w_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
